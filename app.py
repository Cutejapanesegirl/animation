import os
import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
import io
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# KoNLPy(OKT)ëŠ” ì„ íƒì  ì‚¬ìš©: ì„¤ì¹˜/ë¹Œë“œê°€ ë¶ˆê°€í•œ í™˜ê²½ì—ì„œëŠ” ì •ê·œì‹ ê¸°ë°˜ í† í¬ë‚˜ì´ì €ë¡œ ëŒ€ì²´
try:
    from konlpy.tag import Okt  # type: ignore
    _okt: Okt | None = Okt()
except Exception:
    _okt = None

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(layout="centered", page_title="ì• ë‹ˆë©”ì´ì…˜ í”¼ë“œë°± ë¶„ì„ê¸°")

# --- ì•± ì œëª© ë° ì†Œê°œ ---
st.markdown("""
<div style="text-align: center;">
    <h1>ì• ë‹ˆë©”ì´ì…˜ í”¼ë“œë°± ë¶„ì„ê¸°</h1>
    <p>ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ <strong>ê°ì„± ë¶„í¬</strong>ì™€ <strong>ì£¼ìš” í‚¤ì›Œë“œ</strong>ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.</p>
</div>
""", unsafe_allow_html=True)
st.markdown("---")

# --- ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ ë° í•„í„° ---
st.sidebar.markdown("""
<div style="padding: 10px; background-color: #f0f2f6; border-radius: 10px;">
    <h3>íŒŒì¼ ì—…ë¡œë“œ ë° ì„¤ì •</h3>
</div>
""", unsafe_allow_html=True)

uploaded_file = st.sidebar.file_uploader(
    "CSV ë˜ëŠ” Excel íŒŒì¼ ì—…ë¡œë“œ", 
    type=["csv", "xlsx"],
    help="ë¶„ì„í•  ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
)

st.sidebar.markdown("""
<div style="margin-top: 10px; font-size: 0.9em; color: #666;">
    <p><strong>ì°¸ê³ :</strong> íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì§€ ì•Šìœ¼ë©´ ë¡œì»¬ì˜ 'feedback-data.csv' ë˜ëŠ” ì˜ˆì‹œ ë°ì´í„°ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.</p>
</div>
""", unsafe_allow_html=True)

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_data(file_uploader):
    """íŒŒì¼ ì—…ë¡œë”ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê±°ë‚˜, ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¡œì»¬ CSV ë˜ëŠ” ì˜ˆì‹œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""                                     
    if file_uploader:
        try:
            if file_uploader.name.endswith('.csv'):
                df = pd.read_csv(file_uploader)
            else:
                df = pd.read_excel(file_uploader)
            return df
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    else:
        # ë¡œì»¬ ê¸°ë³¸ CSV ê²½ë¡œ í™•ì¸
        default_path = os.path.join(os.getcwd(), "@feedback-data.csv")
        if os.path.exists(default_path):
            try:
                df = pd.read_csv(default_path)
                st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ì–´ ë¡œì»¬ 'feedback-data.csv'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return df
            except Exception as e:
                st.warning(f"ë¡œì»¬ CSVë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # ì˜ˆì‹œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ì• ë‹ˆë©”ì´ì…˜ ì´ë¦„ê³¼ ì¥ë¥´ í‚¤ì›Œë“œ í¬í•¨)
        example_data = {
            'date': pd.to_datetime(['2024-04-01', '2024-04-02', '2024-04-03', '2024-04-04', '2024-04-05',
                                    '2024-04-06', '2024-04-07', '2024-04-08', '2024-04-09', '2024-04-10',
                                    '2024-04-11', '2024-04-12']),
            'product': ['ì§„ê²©ì˜ ê±°ì¸', 'ê·€ë©¸ì˜ ì¹¼ë‚ ', 'ë„ˆì˜ ì´ë¦„ì€', 'ì£¼ìˆ íšŒì „', 'í•˜ì´í!!',
                       'ì„¼ê³¼ ì¹˜íˆë¡œì˜ í–‰ë°©ë¶ˆëª…', 'ì›í€ë§¨', 'ëª¹ ì‚¬ì´ì½” 100', 'ë°ìŠ¤ë…¸íŠ¸', 'ë‚˜ë£¨í† ',
                       'í—Œí„°xí—Œí„°', 'ì•½ì†ì˜ ë„¤ë²„ëœë“œ'],
            'rating': [4.8, 4.9, 5.0, 4.7, 4.8, 5.0, 4.6, 4.7, 4.9, 4.5, 4.8, 4.7],
            'feedback': [
                "ì•¡ì…˜ ìƒì¡´ ê±°ì¸ ì„¸ê³„ê´€",
                "íŒíƒ€ì§€ ì•¡ì…˜ ì• ë‹ˆë©”ì´ì…˜ í€„ë¦¬í‹°",
                "íŒíƒ€ì§€ ë¡œë§¨ìŠ¤ ê°ë™ OST",
                "ì•¡ì…˜ íŒíƒ€ì§€ ì£¼ìˆ  ë°°í‹€",
                "ìŠ¤í¬ì¸  ì„±ì¥ íŒ€ì›Œí¬",
                "íŒíƒ€ì§€ ëª¨í—˜ ë¯¸ì•¼ìí‚¤",
                "ì•¡ì…˜ ì½”ë¯¸ë”” ì‹œì¦ˆì—”",
                "ì•¡ì…˜ ì¼ìƒ ì´ˆëŠ¥ë ¥ ì„±ì¥",
                "ë¯¸ìŠ¤í„°ë¦¬ ì‹¬ë¦¬ ë‡Œì„± ê²Œì„",
                "ì•¡ì…˜ ì„±ì¥ ë‹Œì",
                "íŒíƒ€ì§€ ëª¨í—˜ í—Œí„° ë„¨",
                "ë¯¸ìŠ¤í„°ë¦¬ ì„œìŠ¤íœìŠ¤ ë°˜ì „"
            ]
        }
        df = pd.DataFrame(example_data)
        st.info("íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return df

# --- í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
stopwords_korean = {
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ê³³', 'ë‚´', 'ë‚˜', 'ë„', 'ë¶„', 'ë‹˜', 'ê³¼', 'ì˜', 'ì—', 'ì™€', 'ì€', 'ëŠ”', 'ë‹¤', 'ê³ ', 'ë©´', 'ë¡œ', 'ë¥¼', 'ê²Œ', 'ì˜í•´',
    'ì •ë§', 'ì§„ì§œ', 'ë„ˆë¬´', 'ì•„ì£¼', 'ì•ˆ', 'ëª»', 'ë˜', 'ì˜', 'ì´ë ‡ë‹¤', 'ì €ë ‡ë‹¤', 'ê·¸ë ‡ë‹¤', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'ì•Šë‹¤'
}

def _tokenize_korean(text: str) -> list[str]:
    # OKTê°€ ìˆìœ¼ë©´ ëª…ì‚¬ ê¸°ì¤€, ì—†ìœ¼ë©´ í•œê¸€ 2ì ì´ìƒ í† í° ì •ê·œì‹ ì‚¬ìš©
    text = re.sub(r"[^ê°€-í£\s]", " ", text)
    if _okt is not None:
        try:
            return [n for n in _okt.nouns(text) if len(n) > 1]
        except Exception:
            pass
    return re.findall(r"[ê°€-í£]{2,}", text)

def analyze_sentiment(text):
    """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
    positive_keywords = ['ì¬ë°Œ', 'ê°ë™', 'ì¢‹', 'ì•„ë¦„ë‹µ', 'ê·€ì—½', 'í›Œë¥­', 'ìµœê³ ', 'ë§ˆìŒì— ë“¤', 'ìµœê³ ', 'ì‚¬ë‘', 'ì¶”ì²œ']
    negative_keywords = ['ì‹¤ë§', 'ì•„ì‰½', 'í—ˆë¬´', 'ë³„ë¡œ', 'ì§€ë£¨', 'ëŠë¦¬', 'ë‹¨ì ']

    tokens = _tokenize_korean(text)
    
    pos_score = sum(1 for word in tokens if any(keyword in word for keyword in positive_keywords))
    neg_score = sum(1 for word in tokens if any(keyword in word for keyword in negative_keywords))
    
    if pos_score > neg_score:
        return 'ê¸ì •'
    elif neg_score > pos_score:
        return 'ë¶€ì •'
    else:
        return 'ì¤‘ë¦½'

def extract_keywords(text_series):
    """í”¼ë“œë°± í…ìŠ¤íŠ¸ì—ì„œ ì• ë‹ˆë©”ì´ì…˜ ì¥ë¥´ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ì• ë‹ˆë©”ì´ì…˜ ì¥ë¥´/ë‚´ìš© í‚¤ì›Œë“œ ì‚¬ì „
    genre_keywords = {
        'í•˜ë ˜', 'í›„å®«', 'ë°±í•©', 'GL', 'BL', 'ì•¼ì˜¤ì´', 'ì•¼ë¦¬', 'ì½”ë¯¸ë””', 'ê°œê·¸',
        'íŒíƒ€ì§€', 'ë§ˆë²•', 'SF', 'ì‚¬ì´íŒŒì´', 'ê³µí¬', 'í˜¸ëŸ¬', 'ìŠ¤ë¦´ëŸ¬', 'ë¯¸ìŠ¤í„°ë¦¬',
        'ì•¡ì…˜', 'ë°°í‹€', 'ì „íˆ¬', 'ë¬´í˜‘', 'ê¶Œì„ ì§•ì•…', 'ì •ì˜', 'ë ˆí† ë¦¬ì¹´',
        'ì´ì„¸ê³„', 'ì „ìƒ', 'í˜„ëŒ€', 'ì¤‘ì„¸', 'ë¹…í† ë¦¬ì•„', 'ê·¼ëŒ€', 'ë¯¸ë˜', 'í¬ìŠ¤íŠ¸ì•„í¬ì¹¼ë¦½ìŠ¤',
        'ë¡œë§¨ìŠ¤', 'ìˆœì• ', 'ëŸ¬ë¸Œì½”ë¯¸ë””', 'ì‚¼ê°ê´€ê³„', 'ì—°ì• ', 'ì¹´í’€', 'ë…¸ë˜',
        'ì¼ìƒ', 'ë¼ì´íŠ¸', 'í¸ì•ˆ', 'íë§', 'ë¯¸ì†Œë…€', 'ì†Œë…„ë§Œí™”',
        'ë°°í‹€', 'ê²½ìŸ', 'í† ë„ˆë¨¼íŠ¸', 'íƒˆì¶œ', 'ìƒì¡´', 'í•™êµ', 'í•™ì›',
        'ìŒì•…', 'ë°´ë“œ', 'ì•„ì´ëŒ', 'ì˜¤ì¼€ìŠ¤íŠ¸ë¼', 'ë°œë ˆ', 'ì¶¤',
        'ìš”ë¦¬', 'ìŒì‹', 'ì‹ë‹¹', 'ì¹´í˜', 'ë² ì´í‚¹',
        'ìš´ë™', 'ì•¼êµ¬', 'ì¶•êµ¬', 'ë†êµ¬', 'ë°°êµ¬', 'í…Œë‹ˆìŠ¤', 'ìˆ˜ì˜', 'ìŠ¹ë§ˆ',
        'ê²Œì„', 'VR', 'MMORPG', 'MOBA', 'ì¹´ë“œê²Œì„',
        'ì—­ì‚¬', 'ë‹¤í', 'ì „ê¸°', 'ì‹ í™”', 'ì „ì„¤'
    }
    
    text_combined = " ".join(text_series.astype(str).tolist())
    nouns = _tokenize_korean(text_combined)
    
    # ì¥ë¥´ í‚¤ì›Œë“œë§Œ í•„í„°ë§
    filtered_keywords = []
    for noun in nouns:
        if len(noun) > 1 and noun not in stopwords_korean:
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            for genre in genre_keywords:
                if genre in noun:
                    filtered_keywords.append(genre)
                    break
    
    return Counter(filtered_keywords)

# --- ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ í•¨ìˆ˜ë“¤ ---
def create_user_animation_matrix(df):
    """ì‚¬ìš©ì-ì• ë‹ˆë©”ì´ì…˜ í‰ì  ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
    # dateë¥¼ ì‚¬ìš©ì IDë¡œ ê°„ì£¼ (ì‹¤ì œë¡œëŠ” ë³„ë„ user_id ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨)
    user_ratings = df.groupby(['date', 'product'])['rating'].mean().reset_index()
    user_ratings.columns = ['user_id', 'product', 'rating']
    
    # í”¼ë²— í…Œì´ë¸” ìƒì„±
    matrix = user_ratings.pivot_table(
        index='product', 
        columns='user_id', 
        values='rating', 
        aggfunc='mean'
    ).fillna(0)
    
    return matrix

def get_similar_animations(target_animation, df, top_n=3):
    """íŠ¹ì • ì• ë‹ˆë©”ì´ì…˜ê³¼ ìœ ì‚¬í•œ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ"""
    try:
        matrix = create_user_animation_matrix(df)
        
        if target_animation not in matrix.index:
            return []
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (item-based collaborative filtering)
        target_vector = matrix.loc[target_animation].values.reshape(1, -1)
        similarities = cosine_similarity(target_vector, matrix.values)[0]
        
        similarity_df = pd.DataFrame({
            'animation': matrix.index,
            'similarity': similarities
        })
        
        recommendations = similarity_df[
            similarity_df['animation'] != target_animation
        ].nlargest(top_n, 'similarity')
        
        return recommendations.to_dict('records')
    
    except Exception as e:
        st.warning(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def get_user_based_recommendations(df, target_animations, top_n=5):
    """ì‚¬ìš©ìê°€ ë³¸ ì• ë‹ˆë©”ì´ì…˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ (ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§)"""
    try:
        # ê¸°ë³¸ ì¸ê¸° ì• ë‹ˆë©”ì´ì…˜ ëª©ë¡ (ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ ì‚¬ìš©)
        popular_anime = [
            {'animation': 'ì§„ê²©ì˜ ê±°ì¸', 'similarity': 0.95},
            {'animation': 'ê·€ë©¸ì˜ ì¹¼ë‚ ', 'similarity': 0.93},
            {'animation': 'ì£¼ìˆ íšŒì „', 'similarity': 0.90},
            {'animation': 'ìŠ¤íŒŒì´ íŒ¨ë°€ë¦¬', 'similarity': 0.88},
            {'animation': 'ì›í€ë§¨', 'similarity': 0.85},
            {'animation': 'ë‚˜ì˜ íˆì–´ë¡œ ì•„ì¹´ë°ë¯¸ì•„', 'similarity': 0.83},
            {'animation': 'ì „ìƒí–ˆë”ë‹ˆ ìŠ¬ë¼ì„ì´ì—ˆë˜ ê±´ì— ëŒ€í•˜ì—¬', 'similarity': 0.82},
            {'animation': 'ì•½ì†ì˜ ë„¤ë²„ëœë“œ', 'similarity': 0.80},
            {'animation': 'ë„ì¿„ ë¦¬ë²¤ì €ìŠ¤', 'similarity': 0.78},
            {'animation': 'ë¸”ë£¨ ë½', 'similarity': 0.75},
            {'animation': 'ì²´ì¸ì†Œ ë§¨', 'similarity': 0.73},
            {'animation': 'ìŠ¤íŒŒì´XíŒ¨ë°€ë¦¬', 'similarity': 0.70},
            {'animation': 'ë¸”ë¦¬ì¹˜: ì²œë…„í˜ˆì „í¸', 'similarity': 0.68},
            {'animation': 'ë§ˆê¸°ì•„ ë ˆì½”ë“œ', 'similarity': 0.65}
        ]
        
        matrix = create_user_animation_matrix(df)
        
        # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì¶”ì²œ ë°˜í™˜
        if matrix.empty or len(matrix.index) < 2:
            return popular_anime[:top_n]
        
        available_animations = [a for a in target_animations if a in matrix.index]
        if not available_animations:
            return popular_anime[:top_n]
        
        user_preferences = matrix.loc[available_animations].mean(axis=0)
        user_vector = user_preferences.values.reshape(1, -1)
        similarities = cosine_similarity(user_vector, matrix.values)[0]
        
        similarity_df = pd.DataFrame({
            'animation': matrix.index,
            'similarity': similarities
        })
        
        recommendations = similarity_df[
            ~similarity_df['animation'].isin(target_animations)
        ].nlargest(top_n, 'similarity')
        
        # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì¶”ì²œê³¼ ë³‘í•©
        if len(recommendations) < top_n:
            existing_anime = set(rec['animation'] for rec in recommendations.to_dict('records'))
            additional_recs = [
                rec for rec in popular_anime 
                if rec['animation'] not in existing_anime and 
                   rec['animation'] not in target_animations
            ][:top_n - len(recommendations)]
            
            if additional_recs:
                additional_df = pd.DataFrame(additional_recs)
                recommendations = pd.concat([recommendations, additional_df])
        
        return recommendations.to_dict('records')
    
    except Exception as e:
        st.warning(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- ë©”ì¸ ì•± ë¡œì§ ---
df = load_data(uploaded_file)

if df is not None:
    st.sidebar.subheader("ë°ì´í„° í•„í„°ë§")
    
    # ë‚ ì§œ í•„í„°
    df['date'] = pd.to_datetime(df['date'])
    min_date = df['date'].min()
    max_date = df['date'].max()
    date_range = st.sidebar.slider(
        "ê¸°ê°„ ì„ íƒ",
        min_value=min_date.date(),
        max_value=max_date.date(),
        value=(min_date.date(), max_date.date())
    )
    df_filtered = df[(df['date'].dt.date >= date_range[0]) & (df['date'].dt.date <= date_range[1])]

    # ì œí’ˆëª… í•„í„°
    if 'product' in df.columns:
        unique_products = df['product'].unique().tolist()
        selected_products = st.sidebar.multiselect(
            "ì• ë‹ˆë©”ì´ì…˜ ì„ íƒ",
            options=unique_products,
            default=unique_products
        )
        df_filtered = df_filtered[df_filtered['product'].isin(selected_products)]

    if st.button("ë¶„ì„ ì‹¤í–‰"):
        if df_filtered.empty:
            st.warning("ì„ íƒëœ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner('í”¼ë“œë°±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):

                # ì£¼ìš” ê²°ê³¼ ì‹œê°í™”
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“Š í‰ì  ë¶„í¬ ë¶„ì„")
                    # í‰ì  íˆìŠ¤í† ê·¸ë¨
                    fig_rating = px.histogram(
                        df_filtered,
                        x='rating',
                        nbins=20,
                        title='í‰ì  ë¶„í¬ (1-5ì )',
                        labels={'rating': 'í‰ì ', 'count': 'íšŸìˆ˜'}
                    )
                    fig_rating.update_layout(
                        xaxis=dict(range=[0, 5]),
                        yaxis_title="í‰ê°€ íšŸìˆ˜"
                    )
                    st.plotly_chart(fig_rating, use_container_width=True)
                    
                    # í†µê³„ ì •ë³´
                    avg_rating = df_filtered['rating'].mean()
                    st.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}ì ")
                    
                    # ì¸ìƒì‘ í†µê³„
                    if 'masterpiece' in df_filtered.columns:
                        masterpiece_count = df_filtered['masterpiece'].sum() if df_filtered['masterpiece'].dtype == bool else (df_filtered['masterpiece'] == 'TRUE').sum()
                        st.metric("ì¸ìƒì‘ ì§€ì • íšŸìˆ˜", f"{masterpiece_count}íšŒ")
                
                with col2:
                    st.subheader("ğŸ’¡ ì£¼ìš” í‚¤ì›Œë“œ")
                    keywords = extract_keywords(df_filtered['feedback'])
                    if keywords:
                        # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
                        # OSë³„ í°íŠ¸ ê²½ë¡œ íƒìƒ‰ (Windows/Streamlit Cloud Linux)
                        font_candidates = [
                            r"C:\\Windows\\Fonts\\malgun.ttf",  # Windows
                            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Debian/Ubuntu
                            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",  # Noto CJK
                        ]
                        font_path = next((p for p in font_candidates if os.path.exists(p)), None)
                        wc = WordCloud(
                            font_path=font_path,
                            width=800,
                            height=400,
                            background_color='white'
                        ).generate_from_frequencies(keywords)
                        
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis("off")
                        st.pyplot(fig)
                        
                        # í‚¤ì›Œë“œ í…Œì´ë¸”
                        st.markdown("---")
                        st.markdown("##### ğŸ“Œ ìì£¼ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)")
                        top_keywords = keywords.most_common(10)
                        df_keywords = pd.DataFrame(top_keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
                        st.table(df_keywords)
                    else:
                        st.info("ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                # ì¶”ì²œ ì„¹ì…˜ ì¶”ê°€
                st.markdown("---")
                st.subheader("ğŸ¯ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ")
                st.markdown("ë³¸ ì• ë‹ˆë©”ì´ì…˜ ê¸°ë°˜ìœ¼ë¡œ **ë¹„ìŠ·í•œ ì·¨í–¥ì˜ ì‚¬ëŒë“¤ì´ ì¢‹ì•„í•˜ëŠ”** ì• ë‹ˆë©”ì´ì…˜ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")
                
                # ì• ë‹ˆë©”ì´ì…˜ ê¸°ë°˜ ì¶”ì²œ
                if selected_products:
                    recommendations = get_user_based_recommendations(
                        df_filtered, 
                        selected_products, 
                        top_n=5
                    )
                    if recommendations:
                        st.success(f"âœ¨ **{', '.join(selected_products)}** ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼")
                        for idx, rec in enumerate(recommendations, 1):
                            similarity_score = rec['similarity']
                            animation_name = rec['animation']
                            st.markdown(f"**{idx}. {animation_name}** (ìœ ì‚¬ë„: {similarity_score:.2%})")
                    else:
                        st.info("ì¶”ì²œí•  ì• ë‹ˆë©”ì´ì…˜ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    st.info("ì¶”ì²œì„ ìœ„í•´ ìµœì†Œ 1ê°œ ì´ìƒì˜ ì• ë‹ˆë©”ì´ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

