import os
import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
import io
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# KoNLPy(OKT)ëŠ” ì„ íƒì  ì‚¬ìš©: ì„¤ì¹˜/ë¹Œë“œê°€ ë¶ˆê°€í•œ í™˜ê²½ì—ì„œëŠ” ì •ê·œì‹ ê¸°ë°˜ í† í¬ë‚˜ì´ì €ë¡œ ëŒ€ì²´
try:
    from konlpy.tag import Okt  # type: ignore
    _okt: Okt | None = Okt()
except Exception:
    _okt = None

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(layout="wide", page_title="ì• ë‹ˆë©”ì´ì…˜ í”¼ë“œë°± ë¶„ì„ê¸°")

# --- ì•± ì œëª© ë° ì†Œê°œ ---
st.title("ğŸŒŸ ì• ë‹ˆë©”ì´ì…˜ í”¼ë“œë°± ë¶„ì„ê¸°")
st.markdown("ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ê°ì„± ë¶„í¬**ì™€ **ì£¼ìš” í‚¤ì›Œë“œ**ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")
st.markdown("---")

# --- ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ ë° í•„í„° ---
st.sidebar.header("íŒŒì¼ ì—…ë¡œë“œ ë° ì„¤ì •")
uploaded_file = st.sidebar.file_uploader(
    "CSV ë˜ëŠ” Excel íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx"]
)
st.sidebar.markdown(
    "**ì°¸ê³ :** íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì§€ ì•Šìœ¼ë©´ ë¡œì»¬ì˜ '@feedback-data.csv' ë˜ëŠ” ì˜ˆì‹œ ë°ì´í„°ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤."
)

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_data(file_uploader):
    """íŒŒì¼ ì—…ë¡œë”ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê±°ë‚˜, ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¡œì»¬ CSV ë˜ëŠ” ì˜ˆì‹œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""                                     
    if file_uploader:
        try:
            if file_uploader.name.endswith('.csv'):
                df = pd.read_csv(file_uploader)
            else:
                df = pd.read_excel(file_uploader)
            return df
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    else:
        # ë¡œì»¬ ê¸°ë³¸ CSV ê²½ë¡œ í™•ì¸
        default_path = os.path.join(os.getcwd(), "@feedback-data.csv")
        if os.path.exists(default_path):
            try:
                df = pd.read_csv(default_path)
                st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ì–´ ë¡œì»¬ '@feedback-data.csv'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return df
            except Exception as e:
                st.warning(f"ë¡œì»¬ CSVë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}. ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # ì˜ˆì‹œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ì• ë‹ˆë©”ì´ì…˜ ì´ë¦„ê³¼ ì¥ë¥´ í‚¤ì›Œë“œ í¬í•¨)
        example_data = {
            'date': pd.to_datetime(['2024-04-01', '2024-04-02', '2024-04-03', '2024-04-04', '2024-04-05',
                                    '2024-04-06', '2024-04-07', '2024-04-08', '2024-04-09', '2024-04-10',
                                    '2024-04-11', '2024-04-12']),
            'product': ['Attack on Titan', 'Demon Slayer', 'Your Name', 'Jujutsu Kaisen', 'Haikyuu!!',
                       'Spirited Away', 'One Punch Man', 'Mob Psycho 100', 'Death Note', 'Naruto',
                       'Hunter x Hunter', 'The Promised Neverland'],
            'rating': [4.8, 4.9, 5.0, 4.7, 4.8, 5.0, 4.6, 4.7, 4.9, 4.5, 4.8, 4.7],
            'feedback': [
                "ì•¡ì…˜, ìƒì¡´, ì§„ê²©ì˜ ê±°ì¸ ì„¸ê³„ê´€ì´ ì •ë§ í¥ë¯¸ë¡œì› ì–´ìš”.",
                "íŒíƒ€ì§€, ì•¡ì…˜, ì• ë‹ˆë©”ì´ì…˜ í€„ë¦¬í‹°ê°€ ìµœê³ ì…ë‹ˆë‹¤!",
                "íŒíƒ€ì§€, ë¡œë§¨ìŠ¤, ê°ë™ì ì¸ ìŠ¤í† ë¦¬ì™€ OSTê°€ ì¸ìƒì ì´ì—ìš”.",
                "ì•¡ì…˜, íŒíƒ€ì§€, ì£¼ìˆ  ë°°í‹€ ì‹œìŠ¤í…œì´ ì‹ ì„ í–ˆì–´ìš”.",
                "ìŠ¤í¬ì¸ , ì„±ì¥, íŒ€ì›Œí¬ê°€ ì •ë§ ë©‹ì§„ ì‘í’ˆì´ì—ìš”.",
                "íŒíƒ€ì§€, ëª¨í—˜, ë¯¸ì•¼ìí‚¤ í•˜ì•¼ì˜¤ ê°ë…ì˜ ê±¸ì‘ì…ë‹ˆë‹¤!",
                "ì•¡ì…˜, ì½”ë¯¸ë””, ì‹œì¦ˆì—”ì´ ë„ˆë¬´ ê°•í•´ì„œ ì›ƒê²¨ìš”.",
                "ì•¡ì…˜, ì¼ìƒ, ì´ˆëŠ¥ë ¥ê³¼ ì„±ì¥ ì´ì•¼ê¸°ê°€ ì¢‹ì•„ìš”.",
                "ë¯¸ìŠ¤í„°ë¦¬, ì‹¬ë¦¬, ë‡Œì„± ê²Œì„ì´ ì •ë§ í¥ë¯¸ë¡œì› ìŠµë‹ˆë‹¤.",
                "ì•¡ì…˜, ì„±ì¥, ë‹Œìì˜ ì„¸ê³„ê´€ì´ ë©‹ì¡Œì–´ìš”.",
                "íŒíƒ€ì§€, ëª¨í—˜, í—Œí„° ì‹œí—˜ê³¼ ë„¨ ì‹œìŠ¤í…œì´ ì¢‹ì•„ìš”.",
                "ë¯¸ìŠ¤í„°ë¦¬, ì„œìŠ¤íœìŠ¤, ë°˜ì „ì´ ì¸ìƒì ì´ì—ˆì–´ìš”."
            ]
        }
        df = pd.DataFrame(example_data)
        st.info("íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return df

# --- í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
stopwords_korean = {
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ê³³', 'ë‚´', 'ë‚˜', 'ë„', 'ë¶„', 'ë‹˜', 'ê³¼', 'ì˜', 'ì—', 'ì™€', 'ì€', 'ëŠ”', 'ë‹¤', 'ê³ ', 'ë©´', 'ë¡œ', 'ë¥¼', 'ê²Œ', 'ì˜í•´',
    'ì •ë§', 'ì§„ì§œ', 'ë„ˆë¬´', 'ì•„ì£¼', 'ì•ˆ', 'ëª»', 'ë˜', 'ì˜', 'ì´ë ‡ë‹¤', 'ì €ë ‡ë‹¤', 'ê·¸ë ‡ë‹¤', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'ì•Šë‹¤'
}

def _tokenize_korean(text: str) -> list[str]:
    # OKTê°€ ìˆìœ¼ë©´ ëª…ì‚¬ ê¸°ì¤€, ì—†ìœ¼ë©´ í•œê¸€ 2ì ì´ìƒ í† í° ì •ê·œì‹ ì‚¬ìš©
    text = re.sub(r"[^ê°€-í£\s]", " ", text)
    if _okt is not None:
        try:
            return [n for n in _okt.nouns(text) if len(n) > 1]
        except Exception:
            pass
    return re.findall(r"[ê°€-í£]{2,}", text)

def analyze_sentiment(text):
    """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
    positive_keywords = ['ì¬ë°Œ', 'ê°ë™', 'ì¢‹', 'ì•„ë¦„ë‹µ', 'ê·€ì—½', 'í›Œë¥­', 'ìµœê³ ', 'ë§ˆìŒì— ë“¤', 'ìµœê³ ', 'ì‚¬ë‘', 'ì¶”ì²œ']
    negative_keywords = ['ì‹¤ë§', 'ì•„ì‰½', 'í—ˆë¬´', 'ë³„ë¡œ', 'ì§€ë£¨', 'ëŠë¦¬', 'ë‹¨ì ']

    tokens = _tokenize_korean(text)
    
    pos_score = sum(1 for word in tokens if any(keyword in word for keyword in positive_keywords))
    neg_score = sum(1 for word in tokens if any(keyword in word for keyword in negative_keywords))
    
    if pos_score > neg_score:
        return 'ê¸ì •'
    elif neg_score > pos_score:
        return 'ë¶€ì •'
    else:
        return 'ì¤‘ë¦½'

def extract_keywords(text_series):
    """í”¼ë“œë°± í…ìŠ¤íŠ¸ì—ì„œ ì• ë‹ˆë©”ì´ì…˜ ì¥ë¥´ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ì• ë‹ˆë©”ì´ì…˜ ì¥ë¥´/ë‚´ìš© í‚¤ì›Œë“œ ì‚¬ì „
    genre_keywords = {
        'í•˜ë ˜', 'í›„å®«', 'ë°±í•©', 'GL', 'BL', 'ì•¼ì˜¤ì´', 'ì•¼ë¦¬', 'ì½”ë¯¸ë””', 'ê°œê·¸',
        'íŒíƒ€ì§€', 'ë§ˆë²•', 'SF', 'ì‚¬ì´íŒŒì´', 'ê³µí¬', 'í˜¸ëŸ¬', 'ìŠ¤ë¦´ëŸ¬', 'ë¯¸ìŠ¤í„°ë¦¬',
        'ì•¡ì…˜', 'ë°°í‹€', 'ì „íˆ¬', 'ë¬´í˜‘', 'ê¶Œì„ ì§•ì•…', 'ì •ì˜', 'ë ˆí† ë¦¬ì¹´',
        'ì´ì„¸ê³„', 'ì „ìƒ', 'í˜„ëŒ€', 'ì¤‘ì„¸', 'ë¹…í† ë¦¬ì•„', 'ê·¼ëŒ€', 'ë¯¸ë˜', 'í¬ìŠ¤íŠ¸ì•„í¬ì¹¼ë¦½ìŠ¤',
        'ë¡œë§¨ìŠ¤', 'ìˆœì• ', 'ëŸ¬ë¸Œì½”ë¯¸ë””', 'ì‚¼ê°ê´€ê³„', 'ì—°ì• ', 'ì¹´í’€', 'ë…¸ë˜',
        'ì¼ìƒ', 'ë¼ì´íŠ¸', 'í¸ì•ˆ', 'íë§', 'ë¯¸ì†Œë…€', 'ì†Œë…„ë§Œí™”',
        'ë°°í‹€', 'ê²½ìŸ', 'í† ë„ˆë¨¼íŠ¸', 'íƒˆì¶œ', 'ìƒì¡´', 'í•™êµ', 'í•™ì›',
        'ìŒì•…', 'ë°´ë“œ', 'ì•„ì´ëŒ', 'ì˜¤ì¼€ìŠ¤íŠ¸ë¼', 'ë°œë ˆ', 'ì¶¤',
        'ìš”ë¦¬', 'ìŒì‹', 'ì‹ë‹¹', 'ì¹´í˜', 'ë² ì´í‚¹',
        'ìš´ë™', 'ì•¼êµ¬', 'ì¶•êµ¬', 'ë†êµ¬', 'ë°°êµ¬', 'í…Œë‹ˆìŠ¤', 'ìˆ˜ì˜', 'ìŠ¹ë§ˆ',
        'ê²Œì„', 'VR', 'MMORPG', 'MOBA', 'ì¹´ë“œê²Œì„',
        'ì—­ì‚¬', 'ë‹¤í', 'ì „ê¸°', 'ì‹ í™”', 'ì „ì„¤'
    }
    
    text_combined = " ".join(text_series.astype(str).tolist())
    nouns = _tokenize_korean(text_combined)
    
    # ì¥ë¥´ í‚¤ì›Œë“œë§Œ í•„í„°ë§
    filtered_keywords = []
    for noun in nouns:
        if len(noun) > 1 and noun not in stopwords_korean:
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            for genre in genre_keywords:
                if genre in noun:
                    filtered_keywords.append(genre)
                    break
    
    return Counter(filtered_keywords)

# --- ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ í•¨ìˆ˜ë“¤ ---
def create_user_animation_matrix(df):
    """ì‚¬ìš©ì-ì• ë‹ˆë©”ì´ì…˜ í‰ì  ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
    # dateë¥¼ ì‚¬ìš©ì IDë¡œ ê°„ì£¼ (ì‹¤ì œë¡œëŠ” ë³„ë„ user_id ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨)
    user_ratings = df.groupby(['date', 'product'])['rating'].mean().reset_index()
    user_ratings.columns = ['user_id', 'product', 'rating']
    
    # í”¼ë²— í…Œì´ë¸” ìƒì„±
    matrix = user_ratings.pivot_table(
        index='product', 
        columns='user_id', 
        values='rating', 
        aggfunc='mean'
    ).fillna(0)
    
    return matrix

def get_similar_animations(target_animation, df, top_n=3):
    """íŠ¹ì • ì• ë‹ˆë©”ì´ì…˜ê³¼ ìœ ì‚¬í•œ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ"""
    try:
        matrix = create_user_animation_matrix(df)
        
        if target_animation not in matrix.index:
            return []
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (item-based collaborative filtering)
        target_vector = matrix.loc[target_animation].values.reshape(1, -1)
        similarities = cosine_similarity(target_vector, matrix.values)[0]
        
        similarity_df = pd.DataFrame({
            'animation': matrix.index,
            'similarity': similarities
        })
        
        recommendations = similarity_df[
            similarity_df['animation'] != target_animation
        ].nlargest(top_n, 'similarity')
        
        return recommendations.to_dict('records')
    
    except Exception as e:
        st.warning(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def get_user_based_recommendations(df, target_animations, top_n=3):
    """ì‚¬ìš©ìê°€ ë³¸ ì• ë‹ˆë©”ì´ì…˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ (ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§)"""
    try:
        matrix = create_user_animation_matrix(df)
        
        if matrix.empty or len(matrix.index) < 2:
            return []
        
        available_animations = [a for a in target_animations if a in matrix.index]
        if not available_animations:
            return []
        
        user_preferences = matrix.loc[available_animations].mean(axis=0)
        user_vector = user_preferences.values.reshape(1, -1)
        similarities = cosine_similarity(user_vector, matrix.values)[0]
        
        similarity_df = pd.DataFrame({
            'animation': matrix.index,
            'similarity': similarities
        })
        
        recommendations = similarity_df[
            ~similarity_df['animation'].isin(target_animations)
        ].nlargest(top_n, 'similarity')
        
        return recommendations.to_dict('records')
    
    except Exception as e:
        st.warning(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- ë©”ì¸ ì•± ë¡œì§ ---
df = load_data(uploaded_file)

if df is not None:
    st.sidebar.subheader("ë°ì´í„° í•„í„°ë§")
    
    # ë‚ ì§œ í•„í„°
    df['date'] = pd.to_datetime(df['date'])
    min_date = df['date'].min()
    max_date = df['date'].max()
    date_range = st.sidebar.slider(
        "ê¸°ê°„ ì„ íƒ",
        min_value=min_date.date(),
        max_value=max_date.date(),
        value=(min_date.date(), max_date.date())
    )
    df_filtered = df[(df['date'].dt.date >= date_range[0]) & (df['date'].dt.date <= date_range[1])]

    # ì œí’ˆëª… í•„í„°
    if 'product' in df.columns:
        unique_products = df['product'].unique().tolist()
        selected_products = st.sidebar.multiselect(
            "ì• ë‹ˆë©”ì´ì…˜ ì„ íƒ",
            options=unique_products,
            default=unique_products
        )
        df_filtered = df_filtered[df_filtered['product'].isin(selected_products)]

    if st.button("ë¶„ì„ ì‹¤í–‰"):
        if df_filtered.empty:
            st.warning("ì„ íƒëœ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        else:
            with st.spinner('í”¼ë“œë°±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸš€'):
                st.balloons()

                # ì£¼ìš” ê²°ê³¼ ì‹œê°í™”
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“Š í‰ì  ë¶„í¬ ë¶„ì„")
                    # í‰ì  íˆìŠ¤í† ê·¸ë¨
                    fig_rating = px.histogram(
                        df_filtered,
                        x='rating',
                        nbins=20,
                        title='í‰ì  ë¶„í¬ (1-5ì )',
                        labels={'rating': 'í‰ì ', 'count': 'íšŸìˆ˜'}
                    )
                    fig_rating.update_layout(
                        xaxis=dict(range=[0, 5]),
                        yaxis_title="í‰ê°€ íšŸìˆ˜"
                    )
                    st.plotly_chart(fig_rating, use_container_width=True)
                    
                    # í†µê³„ ì •ë³´
                    avg_rating = df_filtered['rating'].mean()
                    st.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}ì ")
                    
                    # ì¸ìƒì‘ í†µê³„
                    if 'masterpiece' in df_filtered.columns:
                        masterpiece_count = df_filtered['masterpiece'].sum() if df_filtered['masterpiece'].dtype == bool else (df_filtered['masterpiece'] == 'TRUE').sum()
                        st.metric("ì¸ìƒì‘ ì§€ì • íšŸìˆ˜", f"{masterpiece_count}íšŒ")
                
                with col2:
                    st.subheader("ğŸ’¡ ì£¼ìš” í‚¤ì›Œë“œ")
                    keywords = extract_keywords(df_filtered['feedback'])
                    if keywords:
                        # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
                        # OSë³„ í°íŠ¸ ê²½ë¡œ íƒìƒ‰ (Windows/Streamlit Cloud Linux)
                        font_candidates = [
                            r"C:\\Windows\\Fonts\\malgun.ttf",  # Windows
                            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Debian/Ubuntu
                            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",  # Noto CJK
                        ]
                        font_path = next((p for p in font_candidates if os.path.exists(p)), None)
                        wc = WordCloud(
                            font_path=font_path,
                            width=800,
                            height=400,
                            background_color='white'
                        ).generate_from_frequencies(keywords)
                        
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis("off")
                        st.pyplot(fig)
                        
                        # í‚¤ì›Œë“œ í…Œì´ë¸”
                        st.markdown("---")
                        st.markdown("##### ğŸ“Œ ìì£¼ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)")
                        top_keywords = keywords.most_common(10)
                        df_keywords = pd.DataFrame(top_keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
                        st.table(df_keywords)
                    else:
                        st.info("ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                # ì¶”ì²œ ì„¹ì…˜ ì¶”ê°€
                st.markdown("---")
                st.subheader("ğŸ¯ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ")
                st.markdown("ë³¸ ì• ë‹ˆë©”ì´ì…˜ ê¸°ë°˜ìœ¼ë¡œ **ë¹„ìŠ·í•œ ì·¨í–¥ì˜ ì‚¬ëŒë“¤ì´ ì¢‹ì•„í•˜ëŠ”** ì• ë‹ˆë©”ì´ì…˜ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")
                
                # ì¶”ì²œ ëª¨ë“œ ì„ íƒ
                recommendation_mode = st.radio(
                    "ì¶”ì²œ ë°©ì‹ ì„ íƒ",
                    ["ë³¸ ì• ë‹ˆë©”ì´ì…˜ë“¤ ê¸°ë°˜ ì¶”ì²œ", "íŠ¹ì • ì• ë‹ˆë©”ì´ì…˜ ìœ ì‚¬ ì¶”ì²œ"],
                    horizontal=True
                )
                
                if recommendation_mode == "ë³¸ ì• ë‹ˆë©”ì´ì…˜ë“¤ ê¸°ë°˜ ì¶”ì²œ":
                    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì• ë‹ˆë©”ì´ì…˜ë“¤ ê¸°ë°˜ ì¶”ì²œ
                    if selected_products:
                        recommendations = get_user_based_recommendations(
                            df_filtered, 
                            selected_products, 
                            top_n=5
                        )
                        if recommendations:
                            st.success(f"âœ¨ **{', '.join(selected_products)}** ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼")
                            for idx, rec in enumerate(recommendations, 1):
                                similarity_score = rec['similarity']
                                animation_name = rec['animation']
                                st.markdown(f"**{idx}. {animation_name}** (ìœ ì‚¬ë„: {similarity_score:.2%})")
                        else:
                            st.info("ì¶”ì²œí•  ì• ë‹ˆë©”ì´ì…˜ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        st.info("ì¶”ì²œì„ ìœ„í•´ ìµœì†Œ 1ê°œ ì´ìƒì˜ ì• ë‹ˆë©”ì´ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                
                else:
                    # íŠ¹ì • ì• ë‹ˆë©”ì´ì…˜ ìœ ì‚¬ ì¶”ì²œ
                    target_animations_for_rec = st.selectbox(
                        "ê¸°ì¤€ ì• ë‹ˆë©”ì´ì…˜ ì„ íƒ",
                        options=unique_products,
                        help="ì´ ì• ë‹ˆë©”ì´ì…˜ê³¼ ìœ ì‚¬í•œ ì• ë‹ˆë©”ì´ì…˜ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."
                    )
                    
                    if st.button("ìœ ì‚¬ ì• ë‹ˆë©”ì´ì…˜ ì°¾ê¸°"):
                        recommendations = get_similar_animations(
                            target_animations_for_rec,
                            df_filtered,
                            top_n=5
                        )
                        if recommendations:
                            st.success(f"âœ¨ **{target_animations_for_rec}**ì™€(ê³¼) ìœ ì‚¬í•œ ì• ë‹ˆë©”ì´ì…˜")
                            for idx, rec in enumerate(recommendations, 1):
                                similarity_score = rec['similarity']
                                animation_name = rec['animation']
                                st.markdown(f"**{idx}. {animation_name}** (ìœ ì‚¬ë„: {similarity_score:.2%})")
                        else:
                            st.info("ìœ ì‚¬í•œ ì• ë‹ˆë©”ì´ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

